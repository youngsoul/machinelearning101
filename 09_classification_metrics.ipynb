{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a classification model\n",
    "\n",
    "*From the video series: [Introduction to machine learning with scikit-learn](https://github.com/justmarkham/scikit-learn-videos)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "- What is the purpose of **model evaluation**, and what are some common evaluation procedures?\n",
    "- What is the usage of **classification accuracy**, and what are its limitations?\n",
    "- How does a **confusion matrix** describe the performance of a classifier?\n",
    "- What **metrics** can be computed from a confusion matrix?\n",
    "- How can you adjust classifier performance by **changing the classification threshold**?\n",
    "- What is the purpose of an **ROC curve**?\n",
    "- How does **Area Under the Curve (AUC)** differ from classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of model evaluation\n",
    "\n",
    "- Need a way to choose between models: different model types, tuning parameters, and features\n",
    "- Use a **model evaluation procedure** to estimate how well a model will generalize to out-of-sample data\n",
    "- Requires a **model evaluation metric** to quantify the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation procedures\n",
    "\n",
    "1. **Training and testing on the same data**\n",
    "    - Rewards overly complex models that \"overfit\" the training data and won't necessarily generalize\n",
    "2. **Train/test split**\n",
    "    - Split the dataset into two pieces, so that the model can be trained and tested on different data\n",
    "    - Better estimate of out-of-sample performance, but still a \"high variance\" estimate because you are only looking at a single random sample\n",
    "    - Useful due to its speed, simplicity, and flexibility\n",
    "3. **K-fold cross-validation**\n",
    "    - Systematically create \"K\" train/test splits and average the results together\n",
    "    - Even better estimate of out-of-sample performance\n",
    "    - Runs \"K\" times slower than train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation metrics\n",
    "\n",
    "- **Regression problems:** Mean Absolute Error, Mean Squared Error, Root Mean Squared Error\n",
    "- **Classification problems:** Classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification accuracy\n",
    "\n",
    "For binary classification we have a *positive* class and a *negative* class.  Typically the outcome we are looking for is considered the *postive* class.  For example, we are looking to classify who is at risk for diabetes, then having diabetes is the *positive* class in this example.\n",
    "\n",
    "Most of the time, and as we showed in earlier notebooks, measuring accuracy is how we determine if a model was *'good'*.  However, that might not be a very clear measure of the model behavior.\n",
    "\n",
    "Just knowing how many samples were correct and how many samples were wrong is not good enough in some cases.  For example, if the model predicts a person has diabetes but in reality they do not then this person might go on for other testing.  This is called a ***false positive***.  The person was falsely determined to be postive for diabetes when they were not.  The other scenario is that the model predicts that the person does not have diabetes and the disease goes untreated.  This is a ***false negative***.  The person was falsely determined to be negative for diabetes when they actual do.  This case, a ***false negative*** might be much worse than a *false postive*.  \n",
    "\n",
    "It is important to breakdown the classification accuracy further to understand how many ***false positives*** and ***false negatives*** there are.  Depending upon the problem domain, one or the other may be a worse outcome.\n",
    "\n",
    "The ***confusion*** matrix provides information on the ***false negatives*** and ***false positives***.\n",
    "\n",
    "https://towardsdatascience.com/machine-learning-an-error-by-any-other-name-a7760a702c4d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced datasets\n",
    "\n",
    "Most datasets in the wild will be imbalanced, and so it is important to make sure we use proper cross validation and stratification.\n",
    "\n",
    "There is something call, *the null accuracy* which means the accuracy of a model if you should always predict the most frequently occuring outcome.  Clearly any model has to do better than the null accuracy.\n",
    "\n",
    "Scikit learn has a classifier that can easily measure the null accuracy, called *DummyClassifier*.\n",
    "\n",
    "Lets create an imbalanced dataset, such that 90% of the classification targets are false.\n",
    "\n",
    "Then lets run the 'model' and show that if we just predict 'false' our model seems pretty good at 90% accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import numpy as np\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "# skew the target value by make everything not a '9' as false.\n",
    "y = digits.target ==9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data set: (1797, 64)\n",
      "Number of only '9' targets: 180\n",
      "Percent of False (or not '9'): 0.8998330550918197\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the data set: {digits.data.shape}')\n",
    "print(f\"Number of only '9' targets: {sum(y)}\")\n",
    "print(f\"Percent of False (or not '9'): {1-(sum(y)/digits.data.shape[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(digits.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use the DummyClassifier to predict this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DummyClassifier to always pick the most frequent outcome\n",
    "# this is considered the null accuracy\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "\n",
    "predicted_most_frequent = dummy_majority.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(predicted_most_frequent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8955555555555555\n"
     ]
    }
   ],
   "source": [
    "score = dummy_majority.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing you can get such good results, without actually learning anything from the data, when you hear a model is 90% accurate it is important to understand how someone arrived at that and what the data looks like.  90% accurate on the surface does not mean much in isolation.\n",
    "\n",
    "### Using a real classification model.\n",
    "Lets use the exact same data and run a DecisionTreeClassifier to see how it predicts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.9577777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=5)  # try other depth values 2=0.92\n",
    "tree.fit(X_train, y_train)\n",
    "predictions_tree = tree.predict(X_test)\n",
    "tree_score = tree.score(X_test, y_test)\n",
    "print(f\"Test score: {tree_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use the exact same data and run a DecisionTreeClassifier to see how it predicts. \n",
    "\n",
    "We will also use a default DummyClassifier which uses random predictions in the same proportions as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8444444444444444\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dummy_default = DummyClassifier().fit(X_train, y_train)\n",
    "predicted_dummy = dummy_default.predict(X_test)\n",
    "dummy_score = dummy_default.score(X_test, y_test)\n",
    "\n",
    "logreg = LogisticRegression(C=0.1).fit(X_train, y_train)\n",
    "pred_logreg = logreg.predict(X_test)\n",
    "logreg_score = logreg.score(X_test, y_test)\n",
    "print(dummy_score)\n",
    "print(f'{logreg_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that just accuracy is not an informed enough measure.  Even a random prediction is at an 85% percent accuracy.\n",
    "\n",
    "A better way to understand the performance of a classification model, is to look at the **confusion matrix**.\n",
    "\n",
    "The **confusion matrix** gives information on the true negatives, the true positives but also on the misses or errors.  These are the false negatives, which means they were misclassified as negative but should have been positive, and the false positives, which means they were misclassified as positive but should have been negative.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Scikit-learn has a package to calculate the confusion matrix.  Lets look at the confusion matrix for the LogisticRegression problem.\n",
    "\n",
    "The confusion matrix is calculated using the known y_test and the predicted values.\n",
    "\n",
    "When looking at the confusion matrix, the rows represent the true or known values, and the columns represent the predicted values.\n",
    "\n",
    "For the digits example, the positive class is 'predicted a 9'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Confusion Matrix:\n",
      "[[401   2]\n",
      " [  8  39]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "logreg_confusion = confusion_matrix(y_test, pred_logreg)\n",
    "\n",
    "print(f\"Logistic Regression Confusion Matrix:\\n{logreg_confusion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Negative: 401 meaning the model predicted the digit was not a 9 \n",
    "\n",
    "False Positive: 2 meaning the model falsely said the digit was a 9, but in fact it was NOT\n",
    "\n",
    "False Negative: 8 meaning the model predicted the digit was not a 9 but it was\n",
    "\n",
    "True Positive: 39 meaning the model predicted the digit was a 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pima Indian Diabetes Dataset\n",
    "\n",
    "[Pima Indian Diabetes dataset](https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes) from the UCI Machine Learning Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data into a Pandas DataFrame\n",
    "import pandas as pd\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "pima = pd.read_csv('./data/pima-indians-diabetes.csv', header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
       "0         6      148  72    35        0  33.6     0.627   50      1\n",
       "1         1       85  66    29        0  26.6     0.351   31      0\n",
       "2         8      183  64     0        0  23.3     0.672   32      1\n",
       "3         1       89  66    23       94  28.1     0.167   21      0\n",
       "4         0      137  40    35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows of data\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Can we predict the diabetes status of a patient given their health measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age']\n",
    "X = pima[feature_cols]\n",
    "y = pima.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification accuracy:** percentage of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6927083333333334\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null accuracy:** accuracy that could be achieved by always predicting the most frequent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution of the testing set (using a Pandas Series method)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3229166666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of ones\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of zeros\n",
    "1 - y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for binary classification problems coded as 0/1)\n",
    "max(y_test.mean(), 1 - y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.677083\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for multi-class classification problems)\n",
    "y_test.value_counts().head(1) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the **true** and **predicted** response values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0]\n",
      "Pred: [0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "from __future__ import print_function\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', y_pred_class[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Classification accuracy is the **easiest classification metric to understand**\n",
    "- But, it does not tell you the **underlying distribution** of response values\n",
    "- And, it does not tell you what **\"types\" of errors** your classifier is making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "\n",
    "Table that describes the performance of a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted values\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Small confusion matrix](images/09_confusion_matrix_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Every observation in the testing set is represented in **exactly one box**\n",
    "- It's a 2x2 matrix because there are **2 response classes**\n",
    "- The format shown here is **not** universal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic terminology**\n",
    "\n",
    "- **True Positives (TP):** we *correctly* predicted that they *do* have diabetes\n",
    "- **True Negatives (TN):** we *correctly* predicted that they *don't* have diabetes\n",
    "- **False Positives (FP):** we *incorrectly* predicted that they *do* have diabetes (a \"Type I error\")\n",
    "- **False Negatives (FN):** we *incorrectly* predicted that they *don't* have diabetes (a \"Type II error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0]\n",
      "Pred: [0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', y_pred_class[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Large confusion matrix](images/09_confusion_matrix_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics computed from a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Accuracy:** Overall, how often is the classifier correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6927083333333334\n",
      "0.6927083333333334\n"
     ]
    }
   ],
   "source": [
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Error:** Overall, how often is the classifier incorrect?\n",
    "\n",
    "- Also known as \"Misclassification Rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3072916666666667\n",
      "0.30729166666666663\n"
     ]
    }
   ],
   "source": [
    "print((FP + FN) / float(TP + TN + FP + FN))\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sensitivity:** When the actual value is positive, how often is the prediction correct?\n",
    "\n",
    "- How \"sensitive\" is the classifier to detecting positive instances?\n",
    "- Also known as \"True Positive Rate\" or \"Recall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24193548387096775\n",
      "0.24193548387096775\n"
     ]
    }
   ],
   "source": [
    "print(TP / float(TP + FN))\n",
    "print(metrics.recall_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity:** When the actual value is negative, how often is the prediction correct?\n",
    "\n",
    "- How \"specific\" (or \"selective\") is the classifier in predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9076923076923077\n"
     ]
    }
   ],
   "source": [
    "print(TN / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Positive Rate:** When the actual value is negative, how often is the prediction incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09230769230769231\n"
     ]
    }
   ],
   "source": [
    "print(FP / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision:** When a positive value is predicted, how often is the prediction correct?\n",
    "\n",
    "- How \"precise\" is the classifier when predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5555555555555556\n",
      "0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(TP / float(TP + FP))\n",
    "print(metrics.precision_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many other metrics can be computed: F1 score, Matthews correlation coefficient, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Confusion matrix gives you a **more complete picture** of how your classifier is performing\n",
    "- Also allows you to compute various **classification metrics**, and these metrics can guide your model selection\n",
    "\n",
    "**Which metrics should you focus on?**\n",
    "\n",
    "- Choice of metric depends on your **business objective**\n",
    "- **Spam filter** (positive class is \"spam\"): Optimize for **precision or specificity** because false negatives (spam goes to the inbox) are more acceptable than false positives (non-spam is caught by the spam filter)\n",
    "- **Fraudulent transaction detector** (positive class is \"fraud\"): Optimize for **sensitivity** because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting the classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted responses\n",
    "logreg.predict(X_test)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63247571, 0.36752429],\n",
       "       [0.71643656, 0.28356344],\n",
       "       [0.71104114, 0.28895886],\n",
       "       [0.5858938 , 0.4141062 ],\n",
       "       [0.84103973, 0.15896027],\n",
       "       [0.82934844, 0.17065156],\n",
       "       [0.50110974, 0.49889026],\n",
       "       [0.48658459, 0.51341541],\n",
       "       [0.72321388, 0.27678612],\n",
       "       [0.32810562, 0.67189438]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted probabilities of class membership\n",
    "logreg.predict_proba(X_test)[0:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36752429, 0.28356344, 0.28895886, 0.4141062 , 0.15896027,\n",
       "       0.17065156, 0.49889026, 0.51341541, 0.27678612, 0.67189438])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted probabilities for class 1\n",
    "logreg.predict_proba(X_test)[0:10, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the predicted probabilities for class 1\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow plots to appear in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHUZJREFUeJzt3Xm4HFWd//H3JwlIWAMkRgzLZcfgAhgEVGYQlQdBII4gMCCgKALOACIKoqNxRv3BDxV1nBEQkFUWESQDKgMxyCJb2DeRCAHCGhAIAWT9zh/n3KSq6b5d93K7696bz+t5+ulaTlV96/Ty7XOq+7QiAjMzs16j6g7AzMyGFicGMzMrcWIwM7MSJwYzMytxYjAzsxInBjMzK3FiGIYk3Slpq7rjqJOkT0h6SNICSRvXcPzLJX0uT+8h6X+7cMweSSFpTKePlY8XktYZ4LZzJH2kxbotJd3TrKykIyWd2Md+u1LXizsnhiGm2QtK0j6Sruqdj4gNI+LyNvvp6ptIDb4P/EtELBsRN9cZSEScGRHbtCsnaZqkM7oR01AWEVdGxPot1n0vInoT7huew1Xr2t4cJwYbkCGQcNYA7hyMHQ2Bc+m6xfGcrTonhmGooen9PkmzJM2X9LikH+ZiV+T7Z3J3yxaSRkn6hqQHJD0h6TRJKxT2u1de95Skf2s4zjRJ50k6Q9J8YJ987GskPSPpUUk/lbRkYX8h6UBJ90p6TtJ/SFpb0p9yvOcWyzecY9NYJb1F0gJgNHCrpL+22D4kHSTpPklPSjpG0qi8bh9JV0s6VtJTwLS8/LOS7pb0tKRLJK1R2N9HJf1Z0rOSfgqosK7UopO0oaRLJf0tPyZHStoWOBLYNT8et+ayK0g6Kdffw5K+I2l0Xjda0vdz/PcB21d4XnxN0l35HH4haam8bitJcyUdLukx4Bd5+eclzc6xTpf09obdbteiDteW9If8XHlS0pmSxjVsu2lfsbQ4h2KrqtlzuLGuNyjU9T2SPlVYt10+/nO5bg/rq/6sICJ8G0I3YA7wkYZl+wBXNSsDXAN8Ok8vC2yep3uAAMYUtvssMBtYK5c9Hzg9r5sMLAA+CCxJ6qp5pXCcaXl+KukDxVjgvcDmwJh8vLuBQwrHC+BCYHlgQ+AlYEY+/grAXcDeLeqhZayFfa/TRz0GMBNYCVgd+AvwuUJ9vgr8a459LLBTPt478rJvAH/K5ccDzwE7A0sAX8rbf67x8QGWAx4Fvgwslec3K9ThGQ1xXgAcDywDvBW4HvhCXrc/8GdgtXweMxsf0ybPnTsK5a8GvpPXbZVjPhp4Sz7nrYEngU3ysv8ErqhYh+sAH83bTSC9if+oH7HMbfF8XlhHNH8OF+t6GeAh4DP5Mds4n8/kvP5RYMs8vSKwSd2v7+Fyqz0A3xoekPQiWQA8U7i9QOvEcAXwbWB8w36avahmAAcW5tcnvdmPAb4JnFVYtzTwcsML9oo2sR8CXFCYD+ADhfkbgcML8z8ovpk07KtlrIV9t0sM2xbmDwRm5Ol9gAcbyv8O2LcwPyrX+xrAXsC1hXUC5tI8MewO3NwipoVvenl+IilZji0s2x2Ymaf/AOxfWLdN42Pa5LlTLL8d8Nc8vVV+PJcqrD8J+P+F+WVzHfe0q8Mmx55aPO8KsQxGYtgVuLIhjuOBb+XpB4EvAMt36/U7Um7uShqapkbEuN4b6QXZyr7AesCfJd0g6eN9lH078EBh/gFSUpiY1z3UuyIiXgCeatj+oeKMpPUkXSTpsdy99D3Sp+uixwvTLzaZX3YAsVZVjPeBvM9m6yAlgB/nbrFngL+REsAk3lg30WT7XqsBTbu3mliD1AJ5tHDc40ktBxqPS7k+WunrnOdFxN8L86U6jogFpMd8Urv9SZoo6ezcRTMfOIM3PvZ9xTIY1gA26627XH97AG/L6z9JSkgPSPqjpC0G+fgjlhPDMBcR90bE7qQ3k6OB8yQtQ/qk1egR0oup1+qk7oXHSc3uVXtXSBoLrNx4uIb5n5G6OtaNiOVJfehicPQVa1WrNWz/SGG+8VweInXhjCvcxkbEn0h1s3BfktSw78b9rNViXbNjvkRq7fUec/mI2DCvLx03n0M7/TnnUh3n583KwMMV9ve9vL935cd+T9742PcVSxXthn5+CPhjw2O2bEQcABARN0TETqTXxm+Ac/t5/MWWE8MwJ2lPSRMi4nVStxPA68C8fF98kzoL+JKkNSUtS3pxnxMRrwLnATtIer/SBeFptH+TXw6YDyyQtAFwwGCdV5tYq/qKpBUlrQYcDJzTR9njgK9J2hAWXhTeJa+7GNhQ0j8pfZvnIBZ9Km10EbCKpEOULpQvJ2mzvO5xoKf3Am5EPAr8L/ADScsrXXBfW9I/5vLnAgdJWlXSisARFc75i7n8SsDX25zzWcBnJG0k6S2kOr4uIuYUyrSqw+VIXZ7PSpoEfOVNxtJMs+dw0UXAepI+LWmJfNtU0jskLan0m4cVIuIV0vP09X4ef7HlxDD8bQvcqfRNnR8Du0XEi7kr6LvA1bmZvTlwMnA66brE/cDfSRdgiYg78/TZpE+qC4AnSJ9oWzkM+GfShdmf0/8Xfl9axtoPF5Kua9xCenM/qVXBiLiA1OI6O3eN3AF8LK97EtgFOIrU1bIu6WJqs/08R7oouwPwGHAv8KG8+lf5/ilJN+XpvUgX++8CniYl6FXyup8DlwC3AjeRLsC380tSsrmP1KX1nT7O+TLg34Bfkx7ztYHdGoq1qsNvky5aP5uXN4utciwt4mv2HC6uf4503WU3UmvkMRZdXAf4NDAnP577k7qZrALlizRmJflT+jOkbqL7646nvyQFKfbZdcfSLZLmkC6IX1Z3LDa8ucVgC0naQdLSua/5+8DtpG+MmNlixInBinYiNckfIXWX7BZuUpotdtyVZGZmJW4xmJlZybAYSGv8+PHR09NTdxhmZsPKjTfe+GRETOjvdsMiMfT09DBr1qy6wzAzG1YkVfm1/Bu4K8nMzEqcGMzMrMSJwczMSpwYzMysxInBzMxKnBjMzKzEicHMzEqcGMzMrMSJwczMSobFL5+tvZ4jLq71+HOO2r7W45vZ4HGLwczMSpwYzMysxInBzMxKnBjMzKzEicHMzEqcGMzMrMSJwczMSpwYzMysxInBzMxKnBjMzKzEicHMzEqcGMzMrMSD6A2CugewMzMbTG4xmJlZiRODmZmVODGYmVmJE4OZmZU4MZiZWYkTg5mZlTgxmJlZiRODmZmVODGYmVmJE4OZmZV0PDFIGi3pZkkX5fk1JV0nabakcyQt2ekYzMysum60GA4G7i7MHw0cGxHrAE8D+3YhBjMzq6ijiUHSqsD2wIl5XsDWwHm5yKnA1E7GYGZm/dPpFsOPgK8Cr+f5lYFnIuLVPD8XmNRsQ0n7SZolada8efM6HKaZmfXqWGKQ9HHgiYi4cSDbR8QJETElIqZMmDBhkKMzM7NWOvl/DB8AdpS0HbAUsDzwY2CcpDG51bAq8HAHYzAzs37qWIshIr4WEatGRA+wG/CHiNgDmAnsnIvtDVzYqRjMzKz/6vgdw+HAoZJmk645nFRDDGZm1kJX/tozIi4HLs/T9wHv68Zxzcys//zLZzMzK3FiMDOzEicGMzMrcWIwM7MSJwYzMytxYjAzsxInBjMzK3FiMDOzEicGMzMrcWIwM7MSJwYzMytxYjAzs5KuDKJn1g09R1xc6/HnHLV9rcc3GyxuMZiZWYkTg5mZlTgxmJlZiRODmZmVODGYmVmJE4OZmZU4MZiZWYkTg5mZlTgxmJlZiRODmZmVODGYmVmJE4OZmZU4MZiZWYkTg5mZlTgxmJlZiRODmZmVODGYmVmJ/8HNBkXd/55mZoPHLQYzMytxYjAzsxInBjMzK3FiMDOzEicGMzMr6VhikLSUpOsl3SrpTknfzsvXlHSdpNmSzpG0ZKdiMDOz/utki+ElYOuIeA+wEbCtpM2Bo4FjI2Id4Glg3w7GYGZm/dSxxBDJgjy7RL4FsDVwXl5+KjC1UzGYmVn/dfQag6TRkm4BngAuBf4KPBMRr+Yic4FJLbbdT9IsSbPmzZvXyTDNzKygo4khIl6LiI2AVYH3ARv0Y9sTImJKREyZMGFCx2I0M7OySolB0rvezEEi4hlgJrAFME5S71AcqwIPv5l9m5nZ4KraYvjv/A2jAyWtUGUDSRMkjcvTY4GPAneTEsTOudjewIX9jNnMzDqoUmKIiC2BPYDVgBsl/VLSR9tstgowU9JtwA3ApRFxEXA4cKik2cDKwEkDjt7MzAZd5dFVI+JeSd8AZgE/ATaWJODIiDi/SfnbgI2bLL+PdL3BzMyGoKrXGN4t6VhSV9DWwA4R8Y48fWwH4zMzsy6r2mL4T+BEUuvgxd6FEfFIbkWYmdkIUTUxbA+8GBGvAUgaBSwVES9ExOkdi87MzLqu6reSLgPGFuaXzsvMzGyEqZoYlioMb0GeXrozIZmZWZ2qJobnJW3SOyPpvcCLfZQ3M7Nhquo1hkOAX0l6BBDwNmDXjkVlZma1qZQYIuIGSRsA6+dF90TEK50Ly8zM6lL5B27ApkBP3mYTSUTEaR2JyszMalMpMUg6HVgbuAV4LS8OwInBzGyEqdpimAJMjojoZDBmZla/qt9KuoN0wdnMzEa4qi2G8cBdkq4n/ZczABGxY0eiMjOz2lRNDNM6GYSZmQ0dVb+u+kdJawDrRsRlkpYGRnc2NDMzq0PVYbc/D5wHHJ8XTQJ+06mgzMysPlUvPn8R+AAwH9Kf9gBv7VRQZmZWn6qJ4aWIeLl3RtIY0u8YzMxshKmaGP4o6UhgbP6v518B/9O5sMzMrC5VE8MRwDzgduALwG8B/3ObmdkIVPVbSa8DP883MzMbwaqOlXQ/Ta4pRMRagx6RmZnVqj9jJfVaCtgFWGnwwzEzs7pVusYQEU8Vbg9HxI+A7Tscm5mZ1aBqV9ImhdlRpBZEf/7LwczMhomqb+4/KEy/CswBPjXo0ZiZWe2qfivpQ50OxMzMhoaqXUmH9rU+In44OOGYmVnd+vOtpE2B6Xl+B+B64N5OBGVmZvWpmhhWBTaJiOcAJE0DLo6IPTsVmJmZ1aPqkBgTgZcL8y/nZWZmNsJUbTGcBlwv6YI8PxU4tTMhmZlZnap+K+m7kn4HbJkXfSYibu5cWGZmVpeqXUkASwPzI+LHwFxJa3YoJjMzq1HVv/b8FnA48LW8aAngjE4FZWZm9anaYvgEsCPwPEBEPAIs16mgzMysPlUTw8sREeShtyUt024DSatJminpLkl3Sjo4L19J0qWS7s33Kw48fDMzG2xVE8O5ko4Hxkn6PHAZ7f+051XgyxExGdgc+KKkyaR/g5sREesCM/K8mZkNEVW/lfT9/F/P84H1gW9GxKVttnkUeDRPPyfpbmASsBOwVS52KnA56fqFmZkNAW0Tg6TRwGV5IL0+k0Ef++gBNgauAybmpAHwGC1+KCdpP2A/gNVXX30ghzUzswFo25UUEa8Br0taYSAHkLQs8GvgkIiY37Dvhdctmhz3hIiYEhFTJkyYMJBDm5nZAFT95fMC4HZJl5K/mQQQEQf1tZGkJUhJ4cyIOD8vflzSKhHxqKRVgCcGELeZmXVI1cRwfr5VJknAScDdDcNyTwf2Bo7K9xf2Z79mZtZZfSYGSatHxIMRMZBxkT4AfJrU0rglLzuSlBDOlbQv8AD+JzgzsyGlXYvhN8AmAJJ+HRGfrLrjiLgKUIvVH666HzMz6652F5+Lb+xrdTIQMzMbGtolhmgxbWZmI1S7rqT3SJpPajmMzdPk+YiI5TsanZmZdV2fiSEiRncrEDMzGxr6838MZma2GHBiMDOzEicGMzMrcWIwM7MSJwYzMytxYjAzsxInBjMzK3FiMDOzEicGMzMrcWIwM7MSJwYzMytxYjAzsxInBjMzK3FiMDOzEicGMzMrcWIwM7MSJwYzMytxYjAzsxInBjMzK3FiMDOzEicGMzMrcWIwM7MSJwYzMytxYjAzsxInBjMzK3FiMDOzkjF1B2Bmg6fniItrPf6co7av9fg2ONxiMDOzEicGMzMrcWIwM7MSJwYzMytxYjAzs5KOJQZJJ0t6QtIdhWUrSbpU0r35fsVOHd/MzAamky2GU4BtG5YdAcyIiHWBGXnezMyGkI4lhoi4Avhbw+KdgFPz9KnA1E4d38zMBqbb1xgmRsSjefoxYGKrgpL2kzRL0qx58+Z1JzozM6vv4nNEBBB9rD8hIqZExJQJEyZ0MTIzs8VbtxPD45JWAcj3T3T5+GZm1ka3E8N0YO88vTdwYZePb2ZmbXRsED1JZwFbAeMlzQW+BRwFnCtpX+AB4FODcay6Bw4zAz8PbeToWGKIiN1brPpwp45pZmZvnn/5bGZmJU4MZmZW4sRgZmYlTgxmZlbixGBmZiVODGZmVuLEYGZmJU4MZmZW4sRgZmYlTgxmZlbixGBmZiVODGZmVuLEYGZmJU4MZmZW4sRgZmYlTgxmZlbSsT/qMbPFz1D4F7s5R21fdwjDnlsMZmZW4sRgZmYlTgxmZlbixGBmZiVODGZmVuLEYGZmJU4MZmZW4sRgZmYlTgxmZlbixGBmZiVODGZmVuLEYGZmJU4MZmZW4sRgZmYlTgxmZlbixGBmZiVODGZmVuLEYGZmJU4MZmZWUktikLStpHskzZZ0RB0xmJlZc11PDJJGA/8FfAyYDOwuaXK34zAzs+bqaDG8D5gdEfdFxMvA2cBONcRhZmZNjKnhmJOAhwrzc4HNGgtJ2g/YL8++JOmOLsQ2HIwHnqw7iCHCdbGI6yLT0a6LgvUHslEdiaGSiDgBOAFA0qyImFJzSEOC62IR18UirotFXBeLSJo1kO3q6Ep6GFitML9qXmZmZkNAHYnhBmBdSWtKWhLYDZheQxxmZtZE17uSIuJVSf8CXAKMBk6OiDvbbHZC5yMbNlwXi7guFnFdLOK6WGRAdaGIGOxAzMxsGPMvn83MrMSJwczMSoZUYmg3VIakt0g6J6+/TlJP96PsvAr1cKikuyTdJmmGpDXqiLMbqg6fIumTkkLSiP2aYpW6kPSp/Ny4U9Ivux1jt1R4jawuaaakm/PrZLs64uwGSSdLeqLVb72U/CTX1W2SNmm704gYEjfShei/AmsBSwK3ApMbyhwIHJendwPOqTvumurhQ8DSefqAkVgPVesil1sOuAK4FphSd9w1Pi/WBW4GVszzb6077hrr4gTggDw9GZhTd9wdrI9/ADYB7mixfjvgd4CAzYHr2u1zKLUYqgyVsRNwap4+D/iwJHUxxm5oWw8RMTMiXsiz15J+CzISVR0+5T+Ao4G/dzO4LqtSF58H/isingaIiCe6HGO3VKmLAJbP0ysAj3Qxvq6KiCuAv/VRZCfgtEiuBcZJWqWvfQ6lxNBsqIxJrcpExKvAs8DKXYmue6rUQ9G+pE8DI1HbusjN4tUi4uJuBlaDKs+L9YD1JF0t6VpJ23Ytuu6qUhfTgD0lzQV+C/xrd0Ibkvr7njJ0h8Sw9iTtCUwB/rHuWOogaRTwQ2CfmkMZKsaQupO2IrUir5D0roh4ptao6rE7cEpE/EDSFsDpkt4ZEa/XHdhwMJRaDFWGylhYRtIYUhPxqa5E1z2VhgyR9BHg68COEfFSl2LrtnZ1sRzwTuBySXNI/afTR+gF6CrPi7nA9Ih4JSLuB/5CShQjTZW62Bc4FyAirgGWIg00uDjq9zBEQykxVBkqYzqwd57eGfhD5KsrI0jbepC0MXA8KSmM1H5kaFMXEfFsRIyPiJ6I6CFdb9kxIgY0cNgQV+X18RtSawFJ40ldS/d1M8guqVIXDwIfBpD0DlJimNfVKIeO6cBe+dtJmwPPRsSjfW0wZLqSosVQGZL+HZgVEdOBk0hNwtmkiy271RdxZ1Ssh2OAZYFf5WvvD0bEjrUF3SEV62KxULEuLgG2kXQX8BrwlYgYaS3qqnXxZeDnkr5EuhC9zwj8EAmApLNIHwjG52sq3wKWAIiI40jXWLYDZgMvAJ9pu88RWldmZjZAQ6kryczMhgAnBjMzK3FiMDOzEicGMzMrcWIwM7MSJ4bFnKTXJN0i6Q5Jv5K09JvY11aSLsrTO7YZDXWcpAMHcIxpkg4baIx97Hdh7P3YZk7+vUDj8v0l7ZWnT5G0c54+UdLkPH3kYMSd93WQpLslndmm3OW9P/6T9FtJ49qUX9DPOKb2np8Nb04M9mJEbBQR7wReBvYvrsw/iun38yQipkfEUX0UGUcaLbdr8q/lOy4ijouI05os/1xE3JVnBy0xkOrxoxGxR9UNImK7DgyVMZU0kqkNc04MVnQlsI6knjzW/WnAHcBqkraRdI2km3LLYllYOC7+nyXdBPxT744k7SPpp3l6oqQLJN2ab+8HjgLWzq2VY3K5r0i6IY8Z/+3Cvr4u6S+SrgLWbxZ4/mR+nKRZuezHC3FMl/QHYEZOdMfkFtLtknYt7GZ5SRfncz+uNyFK+lne753FuLKv5v1cL2mdXL5pq6b3E7uko4Cx+dzPlPTvkg4plPuupIObbH9ojvuO3vKSjiMNP/27/GOuYvmxks7OrYkLgLGFdQtbO5J+I+nGfH77Nezj2Lx8hqQJednakn6ft7lS0gb5Md0ROCaf19rNyuXtd8nncKukK5o9nlazuscS963eG7Ag348BLiT9v0MP8DqweV43nvR/B8vk+cOBb5KGGXiINB6PSGPTXJTL7AP8NE+fAxySp0eTxrjqoTB+PLANaQx9kT6wXEQaZ/69wO3A0qRhlGcDhzU5j1OA3+dt1yWNG7RUjmMusFIu90ng0hzHRNLQCauQfjn6d9Kb7OhcZue8zUqF2C8H3p3n5wBfz9N7Fc59Wm+MOa7e/VxO/r+I3nrP0z3ATXl6FOm/BlZuOL/eeliG9Kv3O4GNC3GMb1Inh5J+FQzwbuDVwvEXblM4v7GkDwIr5/kA9sjT3yw8njOAdfP0ZqShaUrn2qbc7cCkPD2u7teAb2+8DZkhMaw2YyXdkqevJA078nbggUhjt0ManG4ycLXSEBxLAtcAGwD3R8S9AJLOAEqfOLOtSW+cRMRrwLOSVmwos02+3ZznlyW9wS8HXBD5/yck9TUMxrmRRs+8V9J9OT6ASyOid7z6DwJn5Tgel/RHYFNgPnB9RNyXj3NWLnse8Kn8SXoMKYlMBm7L+zurcH9sH7G1FBFzJD2lNAbWRODmeONQFh8k1cPzOb7zgS1ZVF/N/APwk3yM2yTd1qLcQZI+kadXI9X7U6QPB+fk5WcA5+eW4vtZNBwLwFsad9im3NXAKZLOBc7vI36riRODvRgRGxUX5Bfy88VFpDfX3RvKlbZ7kwT8v4g4vuEYh7Qo30zj+C698883Fqy6vaQ1gcOATSPiaUmnkFoizbZ5M+PLnEhq3bwNOPlN7KdfJG0FfATYIiJekHQ55fMrClKL5pnG50wTLctFxP6SNgO2B26U9N4midBq5GsMVsW1wAcKfejLSFoP+DPQI2ntXG73FtvPIHVRIWm0pBWA50itgV6XAJ/VomsXkyS9ldSFNTX3ly8H7NBHnLtIGpXjWQu4p0mZK4FdcxwTSJ+qr8/r3qc0YucoYFfgKlL31fOkVs5E4GMN+9u1cH9NH7E1ekXSEoX5C4BtSa2XS1rEPVXS0pKWAT6Rl/XlCuCfASS9k9Sd1GgF4OmcFDYgtQ57jSKNYkzez1URMR+4X9Iueb+S9J5cZuFj2lc5SWtHxHUR8U3SiKfFIaFtCHCLwdqKiHmS9gHOktTbHfCNiPhL7mK5WNILpDeq5Zrs4mDgBEn7kkb9PCAirlH6p7E7gN9FxFeUhke+JrdYFgB7RsRNks4h/a/vE6Qhl1t5kPQmvzywf0T8XW/859cLgC3y/gL4akQ8lt8UbwB+CqwDzCR13bwu6WZSEnyI1A1StGLuonmJ1omxmROA2yTdFBF7RMTLkmaSPmW/1lg418MpLEpiJ0ZEX91IAD8DfiHpbuBu4MYmZX4P7J/L3EP6ENDreVKy/Aap7nuT4B7Az/LyJUh/rXlrvv+5pINICaVVuWMk9V6XmpGX2RDi0VVtRMhvmhdFxHl1xzIQuZVyE7BL7zUbs7q4K8msZko/CpsNzHBSsKHALQYzMytxi8HMzEqcGMzMrMSJwczMSpwYzMysxInBzMxK/g9jeI0FHudHdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of predicted probabilities\n",
    "plt.hist(y_pred_prob, bins=8)\n",
    "plt.xlim(0, 1)\n",
    "plt.title('Histogram of predicted probabilities')\n",
    "plt.xlabel('Predicted probability of diabetes')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decrease the threshold** for predicting diabetes in order to **increase the sensitivity** of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict diabetes if the predicted probability is greater than 0.3\n",
    "from sklearn.preprocessing import binarize\n",
    "y_pred_class = binarize([y_pred_prob], 0.3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36752429, 0.28356344, 0.28895886, 0.4141062 , 0.15896027,\n",
       "       0.17065156, 0.49889026, 0.51341541, 0.27678612, 0.67189438])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted probabilities\n",
    "y_pred_prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 0., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted classes with the lower threshold\n",
    "y_pred_class[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n"
     ]
    }
   ],
   "source": [
    "# previous confusion matrix (default threshold of 0.5)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80 50]\n",
      " [16 46]]\n"
     ]
    }
   ],
   "source": [
    "# new confusion matrix (threshold of 0.3)\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7419354838709677\n"
     ]
    }
   ],
   "source": [
    "# sensitivity has increased (used to be 0.24)\n",
    "print(46 / float(46 + 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "# specificity has decreased (used to be 0.91)\n",
    "print(80 / float(80 + 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- **Threshold of 0.5** is used by default (for binary problems) to convert predicted probabilities into class predictions\n",
    "- Threshold can be **adjusted** to increase sensitivity or specificity\n",
    "- Sensitivity and specificity have an **inverse relationship**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves and Area Under the Curve (AUC)\n",
    "\n",
    "**Question:** Wouldn't it be nice if we could see how sensitivity and specificity are affected by various thresholds, without actually changing the threshold?\n",
    "\n",
    "**Answer:** Plot the ROC curve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for diabetes classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROC curve can help you to **choose a threshold** that balances sensitivity and specificity in a way that makes sense for your particular context\n",
    "- You can't actually **see the thresholds** used to generate the curve on the ROC curve itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts a threshold and prints sensitivity and specificity\n",
    "def evaluate_threshold(threshold):\n",
    "    print('Sensitivity:', tpr[thresholds > threshold][-1])\n",
    "    print('Specificity:', 1 - fpr[thresholds > threshold][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.24193548387096775\n",
      "Specificity: 0.9076923076923077\n"
     ]
    }
   ],
   "source": [
    "evaluate_threshold(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.7258064516129032\n",
      "Specificity: 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "evaluate_threshold(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC is the **percentage** of the ROC plot that is **underneath the curve**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7245657568238213\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AUC is useful as a **single number summary** of classifier performance.\n",
    "- If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a **higher predicted probability** to the positive observation.\n",
    "- AUC is useful even when there is **high class imbalance** (unlike classification accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7378233618233618"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate cross-validated AUC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(logreg, X, y, cv=10, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix advantages:**\n",
    "\n",
    "- Allows you to calculate a **variety of metrics**\n",
    "- Useful for **multi-class problems** (more than two response classes)\n",
    "\n",
    "**ROC/AUC advantages:**\n",
    "\n",
    "- Does not require you to **set a classification threshold**\n",
    "- Still useful when there is **high class imbalance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Resources\n",
    "\n",
    "- Blog post: [Simple guide to confusion matrix terminology](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/) by me\n",
    "- Videos: [Intuitive sensitivity and specificity](https://www.youtube.com/watch?v=U4_3fditnWg) (9 minutes) and [The tradeoff between sensitivity and specificity](https://www.youtube.com/watch?v=vtYDyGGeQyo) (13 minutes) by Rahul Patwari\n",
    "- Notebook: [How to calculate \"expected value\"](https://github.com/podopie/DAT18NYC/blob/master/classes/13-expected_value_cost_benefit_analysis.ipynb) from a confusion matrix by treating it as a cost-benefit matrix (by Ed Podojil)\n",
    "- Graphic: How [classification threshold](https://media.amazonwebservices.com/blog/2015/ml_adjust_model_1.png) affects different evaluation metrics (from a [blog post](https://aws.amazon.com/blogs/aws/amazon-machine-learning-make-data-driven-decisions-at-scale/) about Amazon Machine Learning)\n",
    "\n",
    "\n",
    "## ROC and AUC Resources\n",
    "\n",
    "- Lesson notes: [ROC Curves](http://ebp.uga.edu/courses/Chapter%204%20-%20Diagnosis%20I/8%20-%20ROC%20curves.html) (from the University of Georgia)\n",
    "- Video: [ROC Curves and Area Under the Curve](https://www.youtube.com/watch?v=OAl6eAyP-yo) (14 minutes) by me, including [transcript and screenshots](http://www.dataschool.io/roc-curves-and-auc-explained/) and a [visualization](http://www.navan.name/roc/)\n",
    "- Video: [ROC Curves](https://www.youtube.com/watch?v=21Igj5Pr6u4) (12 minutes) by Rahul Patwari\n",
    "- Paper: [An introduction to ROC analysis](http://people.inf.elte.hu/kiss/13dwhdm/roc.pdf) by Tom Fawcett\n",
    "- Usage examples: [Comparing different feature sets](http://research.microsoft.com/pubs/205472/aisec10-leontjeva.pdf) for detecting fraudulent Skype users, and [comparing different classifiers](http://www.cse.ust.hk/nevinZhangGroup/readings/yi/Bradley_PR97.pdf) on a number of popular datasets\n",
    "\n",
    "## Other Resources\n",
    "\n",
    "- scikit-learn documentation: [Model evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- Guide: [Comparing model evaluation procedures and metrics](https://github.com/justmarkham/DAT8/blob/master/other/model_evaluation_comparison.md) by me\n",
    "- Video: [Counterfactual evaluation of machine learning models](https://www.youtube.com/watch?v=QWCSxAKR-h0) (45 minutes) about how Stripe evaluates its fraud detection model, including [slides](http://www.slideshare.net/MichaelManapat/counterfactual-evaluation-of-machine-learning-models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
